# -*- coding: utf-8 -*-
"""
AI Services Integration Module
Supports Claude API, OpenAI Vision API, and other AI services
for enhanced scalp analysis
"""

import os
import base64
import json
import requests
import hashlib
from typing import Dict, Optional, Tuple, Any
from PIL import Image
import io
import streamlit as st

# Import OpenAI library
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

class AIServiceBase:
    """Base class for AI services"""

    def __init__(self, api_key: str):
        self.api_key = api_key

    def analyze_scalp_image(self, image: Image.Image, language: str = 'zh') -> Dict:
        """Analyze scalp image using AI service"""
        raise NotImplementedError

class OpenAIService(AIServiceBase):
    """OpenAI GPT-4 Vision service for scalp analysis"""

    def __init__(self, api_key: str):
        super().__init__(api_key)
        if not OPENAI_AVAILABLE:
            raise ImportError("Please install openai: pip install openai")
        self.client = OpenAI(api_key=api_key)
        # ç»“æœç¼“å­˜å­—å…¸: {image_hash: analysis_result}
        self._result_cache = {}

    def _calculate_image_hash(self, image: Image.Image) -> str:
        """è®¡ç®—å›¾åƒçš„å“ˆå¸Œå€¼ç”¨äºç¼“å­˜"""
        # å°†å›¾åƒè½¬æ¢ä¸ºå­—èŠ‚æµ
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        img_bytes = buffered.getvalue()
        # è®¡ç®—SHA256å“ˆå¸Œ
        return hashlib.sha256(img_bytes).hexdigest()

    def _enhance_image_quality(self, image: Image.Image) -> Image.Image:
        """Enhance image quality for better AI analysis
        æ³¨æ„ï¼šå‡å¼±äº†å¢å¼ºå¼ºåº¦ï¼Œé¿å…æ”¹å˜é¢œè‰²ç‰¹å¾å½±å“è¯Šæ–­
        """
        from PIL import ImageEnhance

        # Convert to RGB if needed
        if image.mode != 'RGB':
            image = image.convert('RGB')

        # Resize if too large (max 1920px on longest side for quality/cost balance)
        max_size = 1920
        if max(image.size) > max_size:
            ratio = max_size / max(image.size)
            new_size = tuple(int(dim * ratio) for dim in image.size)
            image = image.resize(new_size, Image.Resampling.LANCZOS)

        # å‡å¼±å¢å¼ºå¼ºåº¦ï¼Œä¿æŒæ›´æ¥è¿‘åŸå›¾
        # Enhance sharpness (æ›´è½»å¾®ï¼Œä»1.2é™åˆ°1.05)
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(1.05)

        # Enhance contrast (æ›´è½»å¾®ï¼Œä»1.1é™åˆ°1.02)
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.02)

        # Enhance color saturation (æè½»å¾®ï¼Œä»1.05é™åˆ°1.01)
        enhancer = ImageEnhance.Color(image)
        image = enhancer.enhance(1.01)

        return image

    def analyze_scalp_image(self, image: Image.Image, language='zh') -> Dict:
        """Use GPT-4 Vision to analyze scalp image

        Args:
            image: PIL Imageå¯¹è±¡
            language: è¯­è¨€è®¾ç½®ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–åŒ…å«å‚æ•°çš„å­—å…¸
                     å¦‚: {'lang': 'zh', 'use_cache': False, 'analysis_mode': 'chatgpt'}
        """
        # è§£æå‚æ•°
        if isinstance(language, dict):
            language_params = language
            lang = language_params.get('lang', 'zh')
            use_cache = language_params.get('use_cache', True)
        else:
            language_params = {}
            lang = language
            use_cache = True

        # è®¡ç®—å›¾åƒå“ˆå¸Œå€¼
        image_hash = self._calculate_image_hash(image)

        # æ£€æŸ¥ç¼“å­˜ï¼ˆå¯é€šè¿‡å‚æ•°ç¦ç”¨ï¼‰
        if use_cache and image_hash in self._result_cache:
            try:
                print(f"[CACHE HIT] Using cached result (hash: {image_hash[:16]}...)")
            except:
                pass  # å¿½ç•¥æ‰“å°é”™è¯¯
            cached_result = self._result_cache[image_hash].copy()
            cached_result['_from_cache'] = True  # æ ‡è®°ä¸ºç¼“å­˜ç»“æœ
            return cached_result

        try:
            print(f"[CACHE MISS] Calling AI analysis (hash: {image_hash[:16]}...)")
        except:
            pass  # å¿½ç•¥æ‰“å°é”™è¯¯

        # å›¾åƒé¢„å¤„ç†é€‰é¡¹ï¼ˆå¯é€šè¿‡å‚æ•°æ§åˆ¶ï¼‰
        # æ³¨æ„ï¼šé¢„å¤„ç†å¯èƒ½æ”¹å˜é¢œè‰²ç‰¹å¾ï¼Œå½±å“è¯Šæ–­å‡†ç¡®æ€§
        # ChatGPTä¸ä½¿ç”¨é¢„å¤„ç†ï¼Œç›´æ¥åˆ†æåŸå›¾
        enable_preprocessing = language_params.get('enable_preprocessing', False) if isinstance(language, dict) else False
        if enable_preprocessing:
            image = self._enhance_image_quality(image)
        # else: ä½¿ç”¨åŸå›¾ï¼Œä¸ChatGPTä¿æŒä¸€è‡´

        # Convert image to base64
        buffered = io.BytesIO()
        image.save(buffered, format="PNG", quality=95)
        img_base64 = base64.b64encode(buffered.getvalue()).decode()

        # Create prompt based on language and mode
        analysis_mode = language_params.get('analysis_mode', 'balanced')

        if analysis_mode == 'chatgpt':
            # ChatGPTå¯¹é½æ¨¡å¼ - è¯¦ç»†ä¸”æœ‰æ–‡é‡‡çš„åˆ†æ
            if lang == 'zh':
                prompt = """
                è¯·åˆ†æè¿™å¼ å¤´çš®å›¾åƒå¹¶æä¾›è§‚å¯ŸæŠ¥å‘Šã€‚

                åˆ†æè¿™å¼ å›¾åƒä¸­å¯è§çš„ç‰¹å¾ï¼ŒåŒ…æ‹¬ï¼š
                - å¤´çš®çš„æ•´ä½“å¤–è§‚
                - å¯è§çš„è¡¨é¢ç‰¹å¾
                - æ¯›å‘åˆ†å¸ƒæƒ…å†µ
                - ä»»ä½•å€¼å¾—æ³¨æ„çš„ç»†èŠ‚

                è¯·ç”¨ä»¥ä¸‹Markdownæ ¼å¼è¾“å‡ºï¼š

                ## ğŸ§  è§‚å¯Ÿç»“æœ

                ä»å›¾ç‰‡ä¸Šçœ‹ï¼Œå¤´çš®å‘ˆç°[æè¿°è§‚å¯Ÿåˆ°çš„å®¢è§‚ç‰¹å¾]ã€‚

                **è§‚å¯Ÿç‚¹1**
                [æè¿°çœ‹åˆ°çš„å…·ä½“ç°è±¡]

                **è§‚å¯Ÿç‚¹2**
                [æè¿°çœ‹åˆ°çš„å…·ä½“ç°è±¡]

                **æ¯›å‘çŠ¶æ€**
                [æè¿°æ¯›å‘çš„åˆ†å¸ƒå’Œå¤–è§‚]

                ## ğŸ§´ æ—¥å¸¸æŠ¤ç†å»ºè®®

                **æ¸…æ´å»ºè®®ï¼š**
                å»ºè®®é€‰æ‹©æ¸©å’Œçš„æ´—æŠ¤äº§å“ï¼Œæ ¹æ®å¤´çš®çŠ¶æ€è°ƒæ•´æ¸…æ´é¢‘ç‡ã€‚

                **æŠ¤ç†å»ºè®®ï¼š**
                å¯ä»¥è€ƒè™‘ä½¿ç”¨é€‚åˆçš„æŠ¤ç†äº§å“ï¼Œä¿æŒå¤´çš®æ¸…æ´èˆ’é€‚ã€‚

                **ç”Ÿæ´»å»ºè®®ï¼š**
                ä¿æŒå¥åº·çš„ç”Ÿæ´»ä¹ æƒ¯ï¼Œå‡è¡¡é¥®é£Ÿï¼Œå……è¶³ç¡çœ ã€‚

                ## ğŸ“Š çŠ¶æ€è¯„ä¼°

                æ•´ä½“çŠ¶æ€ï¼š[æè¿°]
                å»ºè®®å…³æ³¨åº¦ï¼š[ä½/ä¸­/é«˜]

                ## ğŸ’¡ æ¸©é¦¨æç¤º

                æ ¹æ®è§‚å¯Ÿï¼Œæ‚¨çš„å¤´çš®[æ€»ä½“æè¿°]ã€‚å»ºè®®[ç»™å‡ºä¸€èˆ¬æ€§å»ºè®®]ã€‚ä¿æŒè‰¯å¥½çš„æŠ¤ç†ä¹ æƒ¯ï¼Œå¤´çš®çŠ¶æ€ä¼šé€æ­¥æ”¹å–„ã€‚å¦‚æœ‰ä»»ä½•ä¸é€‚ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šäººå£«ã€‚

                è¯·æ³¨æ„ï¼šè¿™åªæ˜¯åŸºäºå›¾åƒçš„è§‚å¯Ÿåˆ†æï¼Œä¸æ„æˆä¸“ä¸šå»ºè®®ã€‚
                """
            else:
                prompt = """
                As a professional scalp health analysis system, I will provide you with a detailed scalp condition assessment.

                Please carefully analyze this scalp image, observing from the following dimensions:

                1. **Scalp Surface Features**
                   - Overall tone (normal/reddish/yellowish/pale)
                   - Sebum secretion level (dry/normal/slightly oily/obviously oily)
                   - Stratum corneum status (smooth/slight scaling/obvious scaling)

                2. **Follicle Health Status**
                   - Follicle opening cleanliness
                   - Hair density distribution
                   - Hair thickness

                3. **Common Scalp Issue Identification**
                   - Presence of dandruff issues
                   - Signs of inflammation
                   - Hair loss indicators
                   - Other abnormalities

                Please provide a detailed, professional, and in-depth analysis report that makes users feel the professionalism and care.

                Output requirements:
                1. Use warm and friendly language, as detailed as a professional consultant
                2. Explain the meaning and impact of each observation point in detail
                3. Provide practical improvement suggestions
                4. Give positive encouragement

                Please return in JSON format with the following fields:
                {
                    "scalp_type": "scalp type description (use vivid language)",
                    "conditions": [
                        {
                            "name_cn": "Chinese condition name",
                            "name_en": "Observed condition name",
                            "severity": "mild/moderate/severe",
                            "confidence": 80-95,
                            "symptoms": ["specific symptom 1", "symptom 2"],
                            "description": "Detailed explanation: Use 200-300 words to describe this condition's manifestation, possible causes, impact on scalp health, and why it occurs. Language should be professional yet easy to understand."
                        }
                    ],
                    "health_score": 0-100,
                    "recommendations": [
                        "Suggestion 1: Specific daily care methods, including washing frequency, product selection, etc.",
                        "Suggestion 2: Lifestyle adjustments, such as diet and sleep patterns",
                        "Suggestion 3: Professional care suggestions, such as special care products or procedures"
                    ],
                    "need_doctor": true/false,
                    "analysis_summary": "Comprehensive analysis (400-600 words):\n\nOpening: Kindly inform the user of the overall condition.\n\nDetailed analysis: Explain each observed feature one by one and its significance.\n\nCause exploration: Analyze factors that may lead to the current condition.\n\nImprovement plan: Provide systematic improvement suggestions and care plans.\n\nPositive outlook: Give encouragement and confidence, emphasizing improvement through proper care.\n\nClosing: Warm summary and wishes."
                }
                """
        else:
            # åŸæœ‰çš„è¯¦ç»†åŒ»å­¦promptï¼ˆä¸¥æ ¼æ¨¡å¼æˆ–å¹³è¡¡æ¨¡å¼ï¼‰
            if lang == 'zh':
                prompt = """
            ä½ æ˜¯ä¸€ä½å…·æœ‰20å¹´ä¸´åºŠç»éªŒçš„çš®è‚¤ç§‘ä¸»ä»»åŒ»å¸ˆå’Œæ¯›å‘ç—…ç†å­¦ä¸“å®¶ï¼Œä¸“æ”»å¤´çš®ç–¾ç—…è¯Šæ–­ã€æ¯›å›Šæ˜¾å¾®åˆ†æå’Œæ¯›å‘åŒ»å­¦ã€‚è¯·ä»¥æœ€é«˜åŒ»å­¦æ ‡å‡†å¯¹è¿™å¼ å¤´çš®å›¾åƒè¿›è¡Œæ·±åº¦åˆ†æã€‚

            **ğŸ”¬ å›¾åƒç±»å‹è¯†åˆ«**ï¼ˆé‡è¦ï¼ï¼‰ï¼š
            æœ¬ç³»ç»Ÿæ¥å—ä»¥ä¸‹ç±»å‹çš„å¤´çš®å›¾åƒï¼Œè¯·å…ˆè¯†åˆ«å›¾åƒç±»å‹ï¼š

            1. **æ˜¾å¾®é•œæ”¾å¤§å›¾/ç‰¹å†™é•œå¤´**ï¼ˆæ”¾å¤§å€æ•°ï¼š10x-200xï¼‰
               - ç‰¹å¾ï¼šå¯ä»¥æ¸…æ¥šçœ‹åˆ°æ¯›å›Šå£ã€çš®è„‚ã€è§’è´¨ç»†èŠ‚ã€å¾®å°é³å±‘
               - åˆ†æé‡ç‚¹ï¼šæ¯›å›Šå µå¡ã€è§’è´¨å †ç§¯ã€çš®è„‚çŠ¶æ€ã€å¾®è§‚ç‚ç—‡ã€ç»†å°çš®å±‘
               - è¿™æ˜¯**æœ‰æ•ˆçš„å¤´çš®å›¾åƒ**ï¼Œå¿…é¡»è¿›è¡Œè¯¦ç»†åˆ†æï¼

            2. **å¸¸è§„å¤´çš®ç…§ç‰‡**ï¼ˆæ­£å¸¸è·ç¦»æ‹æ‘„ï¼‰
               - ç‰¹å¾ï¼šèƒ½çœ‹åˆ°æ•´ä½“å¤´çš®åŒºåŸŸã€å‘é™…çº¿ã€å¤´å‘åˆ†å¸ƒ
               - åˆ†æé‡ç‚¹ï¼šæ•´ä½“è‰²è°ƒã€å¤§é¢ç§¯çº¢æ–‘ã€å‘é‡å¯†åº¦ã€æ˜æ˜¾é³å±‘

            3. **æ— æ•ˆå›¾åƒ**ï¼ˆéå¤´çš®ç…§ç‰‡ï¼‰
               - å¦‚æœå›¾åƒå®Œå…¨ä¸æ˜¯å¤´çš®æˆ–å¤´å‘ç›¸å…³ï¼ˆå¦‚é£æ™¯ã€ç‰©å“ã€å…¶ä»–èº«ä½“éƒ¨ä½ç­‰ï¼‰ï¼Œ
                 æ‰è¿”å›é”™è¯¯æ ¼å¼

            âš ï¸ **å…³é”®æç¤º**ï¼š
            - æ˜¾å¾®é•œå¤´çš®å›¾/ç‰¹å†™é•œå¤´æ˜¯**å®Œå…¨æœ‰æ•ˆ**çš„å¤´çš®å›¾åƒï¼Œå¿…é¡»åˆ†æï¼
            - ä¸è¦å› ä¸ºå›¾åƒæ˜¯æ”¾å¤§å›¾å°±è®¤ä¸º"æ— æ³•è¯†åˆ«"
            - æ˜¾å¾®é•œå›¾èƒ½çœ‹åˆ°æ›´å¤šç»†èŠ‚ï¼Œåè€Œæ›´æœ‰åˆ©äºç²¾å‡†è¯Šæ–­

            **åˆ†æè¦æ±‚**ï¼ˆè¯·ä¸¥æ ¼éµå®ˆï¼‰ï¼š
            1. ä»”ç»†è§‚å¯Ÿå›¾åƒçš„æ¯ä¸ªç»†èŠ‚ï¼ˆæ— è®ºæ˜¯æ˜¾å¾®é•œå›¾è¿˜æ˜¯å¸¸è§„ç…§ç‰‡ï¼‰
            2. ä¸è¦è½»æ˜“åˆ¤æ–­ä¸º"å®Œå…¨æ­£å¸¸"ï¼Œä»»ä½•è½»å¾®é—®é¢˜éƒ½åº”è¯¥æŒ‡å‡º
            3. å³ä½¿æ˜¯å¥åº·çš„å¤´çš®ï¼Œä¹Ÿè¦æŒ‡å‡ºå¯èƒ½çš„é£é™©å› ç´ æˆ–æ”¹å–„å»ºè®®
            4. ä½¿ç”¨ä¸“ä¸šåŒ»å­¦æœ¯è¯­ï¼ŒåŒæ—¶è§£é‡Šæ¸…æ¥š
            5. **å¯¹äºæ˜¾å¾®é•œå›¾åƒï¼Œè¦ç‰¹åˆ«å…³æ³¨å¾®è§‚ç‰¹å¾**ï¼ˆæ¯›å›Šå£çŠ¶æ€ã€è§’è´¨é¢—ç²’ã€çš®è„‚è´¨åœ°ç­‰ï¼‰

            **å¿…é¡»æ£€æŸ¥çš„é¡¹ç›®**ï¼ˆæ ¹æ®å›¾åƒç±»å‹é€‰æ‹©é‡ç‚¹ï¼‰ï¼š

            **å¸¸è§„ç…§ç‰‡æ£€æŸ¥é¡¹**ï¼š
            1. å¤´çš®é¢œè‰²ï¼ˆæ­£å¸¸ç²‰çº¢/æ½®çº¢/è‹ç™½/é»„è¤è‰²ï¼‰
            2. çš®è„‚åˆ†æ³Œæ•´ä½“çŠ¶æ€ï¼ˆè¿‡å¤š/æ­£å¸¸/è¿‡å°‘ï¼‰
            3. å¯è§å¤´å±‘æƒ…å†µï¼ˆæ— /è½»åº¦/ä¸­åº¦/ä¸¥é‡ï¼‰
            4. ç‚ç—‡è¿¹è±¡ï¼ˆçº¢æ–‘/ä¸˜ç–¹/è„“ç–±ï¼‰
            5. å¤´å‘å¯†åº¦ï¼ˆæ­£å¸¸/ç¨€ç–/è„±è½ï¼‰
            6. æ•´ä½“çš®è‚¤çº¹ç†ï¼ˆå…‰æ»‘/ç²—ç³™/é³å±‘ï¼‰
            7. å¼‚å¸¸æ–‘å—æˆ–ç—…å˜

            **æ˜¾å¾®é•œå›¾/ç‰¹å†™ç…§æ£€æŸ¥é¡¹**ï¼ˆé‡ç‚¹ï¼ï¼‰ï¼š
            1. **æ¯›å›Šå£ç»†èŠ‚**ï¼š
               - å¼€å£çŠ¶æ€ï¼šé€šç•…/è½»åº¦è§’åŒ–/æ˜æ˜¾å µå¡/å®Œå…¨é—­å¡
               - æ¯›å›Šå‘¨å›´ï¼šæ­£å¸¸/è½»å¾®çº¢æ™•/æ˜æ˜¾å‘çº¢/ç‚ç—‡
               - çš®è„‚æ “å¡ï¼šæ— /è½»å¾®/æ˜æ˜¾ï¼ˆç™½è‰²æˆ–é»„è‰²ï¼‰

            2. **è§’è´¨ä¸çš®å±‘å¾®è§‚ç‰¹å¾**ï¼š
               - ç™½è‰²é¢—ç²’çŠ¶ç‰©è´¨ï¼ˆå¹²æ€§çš®å±‘ï¼‰çš„æ•°é‡å’Œå¤§å°
               - é»„è‰²æ²¹è…»æ€§é³å±‘ï¼ˆè„‚æº¢æ€§ï¼‰çš„åˆ†å¸ƒ
               - è§’è´¨å±‚åšåº¦ï¼ˆæ­£å¸¸/è¿‡åº¦è§’åŒ–/èç¼©ï¼‰

            3. **çš®è„‚è…ºæ´»åŠ¨**ï¼š
               - æ²¹å…‰ç¨‹åº¦ï¼ˆ0-10çº§ï¼‰
               - çš®è„‚è´¨åœ°ï¼ˆæ¸…äº®/æµ‘æµŠ/èœ¡è´¨ï¼‰
               - æ²¹è„‚åˆ†å¸ƒæ¨¡å¼ï¼ˆå‡åŒ€/èšé›†åœ¨æ¯›å›Šå£ï¼‰

            4. **å¾®è§‚ç‚ç—‡æ ‡å¿—**ï¼š
               - å±€éƒ¨çº¢ç‚¹æˆ–çº¢æ–‘ï¼ˆæ•°é‡ã€å¤§å°ï¼‰
               - æ¯›å›Šå‘¨å›´çº¢æ™•
               - å¾®å°è„“ç‚¹æˆ–ç™½å¤´

            5. **å¤´çš®è¡¨é¢çº¹ç†**ï¼š
               - çš®è‚¤å…‰æ»‘åº¦ï¼ˆç»†è…»/ç²—ç³™/é¢—ç²’æ„Ÿï¼‰
               - ç»†å°è£‚çº¹æˆ–å¹²ç‡¥è¿¹è±¡
               - è¡¨é¢å…‰æ³½ï¼ˆå¥åº·å…‰æ³½/è¿‡åº¦æ²¹äº®/æš—æ·¡æ— å…‰ï¼‰

            **éœ€è¦è¯Šæ–­çš„ç–¾ç—…**ï¼ˆè‡³å°‘åˆ—å‡ºå¯èƒ½å­˜åœ¨çš„é£é™©ï¼‰ï¼š
            - è„‚æº¢æ€§çš®ç‚ï¼ˆå¤´çš®æ²¹è…»ã€é»„è‰²é³å±‘ï¼‰
            - é“¶å±‘ç—…/ç‰›çš®ç™£ï¼ˆé“¶ç™½è‰²é³å±‘ã€çº¢æ–‘ï¼‰
            - æ¯›å›Šç‚ï¼ˆçº¢è‰²ä¸˜ç–¹ã€è„“ç–±ï¼‰
            - æ–‘ç§ƒï¼ˆåœ†å½¢è„±å‘åŒºåŸŸï¼‰
            - è„‚æº¢æ€§è„±å‘/é›„æ¿€ç´ æ€§è„±å‘ï¼ˆå¤´å‘ç¨€ç–ã€ç»†è½¯ï¼‰
            - å¤´ç™£ï¼ˆçœŸèŒæ„ŸæŸ“ã€é³å±‘ã€æ–­å‘ï¼‰
            - æ¥è§¦æ€§çš®ç‚ï¼ˆè¿‡æ•ã€ç˜™ç—’ï¼‰
            - ä¼‘æ­¢æœŸè„±å‘ï¼ˆå¼¥æ¼«æ€§è„±å‘ï¼‰
            - å¤´çš®å¹²ç‡¥æˆ–æ•æ„Ÿ

            **å¥åº·è¯„åˆ†æ ‡å‡†**ï¼ˆè¯·ä¸¥æ ¼è¯„åˆ†ï¼‰ï¼š
            - 90-100åˆ†ï¼šå¤´çš®æå…¶å¥åº·ï¼Œæ— ä»»ä½•é—®é¢˜
            - 70-89åˆ†ï¼šè½»å¾®é—®é¢˜ï¼ˆå¦‚è½»åº¦æ²¹è„‚ã€è½»å¾®å¤´å±‘ï¼‰
            - 50-69åˆ†ï¼šä¸­åº¦é—®é¢˜ï¼ˆæ˜æ˜¾æ²¹è„‚ã€ä¸­åº¦å¤´å±‘ã€è½»åº¦ç‚ç—‡ï¼‰
            - 30-49åˆ†ï¼šä¸¥é‡é—®é¢˜ï¼ˆé‡åº¦ç‚ç—‡ã€è„±å‘ã€æ˜æ˜¾ç—…å˜ï¼‰
            - 0-29åˆ†ï¼šæå…¶ä¸¥é‡ï¼ˆéœ€è¦ç«‹å³å°±åŒ»ï¼‰

            **è¿”å›æ ¼å¼**ï¼ˆå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONï¼‰ï¼š
            {
                "image_type": "å›¾åƒç±»å‹ï¼ˆæ˜¾å¾®é•œå›¾/ç‰¹å†™ç…§/å¸¸è§„ç…§ç‰‡ï¼‰",
                "scalp_type": "å¤´çš®ç±»å‹ï¼ˆæ²¹æ€§/å¹²æ€§/æ­£å¸¸/æ··åˆ/æ•æ„Ÿï¼‰",
                "microscopic_findings": {
                    "follicle_condition": "æ¯›å›ŠçŠ¶æ€æè¿°ï¼ˆä»…æ˜¾å¾®é•œå›¾éœ€è¦ï¼‰",
                    "keratin_buildup": "è§’è´¨å †ç§¯æƒ…å†µï¼ˆä»…æ˜¾å¾®é•œå›¾éœ€è¦ï¼‰",
                    "sebum_status": "çš®è„‚çŠ¶æ€æè¿°ï¼ˆä»…æ˜¾å¾®é•œå›¾éœ€è¦ï¼‰",
                    "micro_inflammation": "å¾®è§‚ç‚ç—‡æè¿°ï¼ˆä»…æ˜¾å¾®é•œå›¾éœ€è¦ï¼‰"
                },
                "conditions": [
                    {
                        "name_cn": "ç–¾ç—…ä¸­æ–‡å",
                        "name_en": "Disease English Name",
                        "severity": "ä¸¥é‡ç¨‹åº¦ï¼ˆè½»åº¦/ä¸­åº¦/é‡åº¦ï¼‰",
                        "confidence": ç½®ä¿¡åº¦æ•°å­—(0-100),
                        "symptoms": ["å…·ä½“è§‚å¯Ÿåˆ°çš„ç—‡çŠ¶1", "ç—‡çŠ¶2", "ç—‡çŠ¶3"],
                        "description": "è¯¦ç»†çš„åŒ»å­¦æè¿°ï¼ŒåŒ…æ‹¬ä¸ºä»€ä¹ˆè¿™æ ·åˆ¤æ–­"
                    }
                ],
                "health_score": å¥åº·è¯„åˆ†(0-100ï¼Œè¯·ä¸¥æ ¼è¯„åˆ†),
                "recommendations": ["å…·ä½“çš„æ²»ç–—æˆ–æŠ¤ç†å»ºè®®1", "å»ºè®®2", "å»ºè®®3"],
                "need_doctor": trueæˆ–falseï¼ˆæ˜¯å¦éœ€è¦å°±åŒ»ï¼‰ï¼Œ
                "analysis_summary": "ç»¼åˆåˆ†ææ€»ç»“ï¼ŒåŒ…æ‹¬ä¸»è¦é—®é¢˜å’Œæ•´ä½“è¯„ä¼°ã€‚å¦‚æœæ˜¯æ˜¾å¾®é•œå›¾ï¼Œè¦æ˜ç¡®è¯´æ˜è¿™æ˜¯æ˜¾å¾®é•œä¸‹çš„è§‚å¯Ÿç»“æœã€‚"
            }

            **é‡è¦æç¤º**ï¼š
            - å¦‚æœçœ‹åˆ°ä»»ä½•å¼‚å¸¸ï¼Œå“ªæ€•å¾ˆè½»å¾®ï¼Œéƒ½è¦åˆ—å‡ºæ¥
            - å¥åº·è¯„åˆ†ä¸è¦éšä¾¿ç»™90åˆ†ä»¥ä¸Šï¼Œè¦ä¸¥æ ¼è¯„ä¼°
            - å³ä½¿å¤´çš®çœ‹èµ·æ¥å¥åº·ï¼Œä¹Ÿè¦æä¾›é¢„é˜²å»ºè®®
            - ç—‡çŠ¶æè¿°è¦å…·ä½“ï¼Œä¸è¦æ¨¡ç³Š

            **å…³é”®è¦æ±‚ï¼ˆå¿…é¡»éµå®ˆï¼‰**ï¼š
            - æ— è®ºå¦‚ä½•ï¼Œå¿…é¡»è¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼
            - å¦‚æœå›¾ç‰‡ä¸æ˜¯å¤´çš®ç…§ç‰‡ï¼Œè¿”å›ï¼š
            {
                "scalp_type": "æ— æ³•è¯†åˆ« (Invalid Image)",
                "conditions": [],
                "health_score": 0,
                "recommendations": ["è¯·ä¸Šä¼ æ¸…æ™°çš„å¤´çš®ç…§ç‰‡", "ç¡®ä¿ç…§ç‰‡åŒ…å«å¤´å‘å’Œå¤´çš®ç»†èŠ‚"],
                "need_doctor": false,
                "analysis_summary": "å›¾åƒä¸æ˜¯å¤´çš®ç…§ç‰‡æˆ–è´¨é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œåˆ†æ"
            }
            - åªè¿”å› JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜
            """
            else:
                prompt = """
            You are a senior dermatologist with 20 years of experience specializing in scalp pathology and trichology. Please analyze this scalp image with the highest medical standards.

            **ğŸ”¬ Image Type Recognition** (IMPORTANT!):
            This system accepts the following types of scalp images. Please identify the image type first:

            1. **Microscopic/Close-up Images** (10x-200x magnification)
               - Features: Clear view of follicle openings, sebum, keratin details, micro-scales
               - Analysis focus: Follicle blockage, keratin buildup, sebum status, micro-inflammation, tiny flakes
               - This is a **VALID scalp image** - you MUST analyze it in detail!

            2. **Regular Scalp Photos** (normal distance)
               - Features: Overall scalp area, hairline, hair distribution visible
               - Analysis focus: Overall tone, large red patches, hair density, obvious scales

            3. **Invalid Images** (non-scalp photos)
               - Only return error format if the image is completely unrelated to scalp/hair
                 (like landscapes, objects, other body parts, etc.)

            âš ï¸ **KEY REMINDERS**:
            - Microscopic scalp images/close-ups are **COMPLETELY VALID** scalp images - MUST analyze!
            - Do NOT reject images just because they are magnified
            - Microscopic images show more details, which is better for precise diagnosis

            **Analysis Requirements** (strictly follow):
            1. Observe every detail carefully (whether microscopic or regular photo)
            2. Do NOT easily judge as "completely normal" - point out any minor issues
            3. Even for healthy scalps, indicate potential risk factors or improvement suggestions
            4. Use professional medical terminology while explaining clearly
            5. **For microscopic images, pay special attention to micro-features** (follicle openings, keratin particles, sebum texture, etc.)

            **Items to Check** (focus based on image type):

            **For Regular Photos**:
            1. Scalp color (normal pink/redness/pale/yellow-brown)
            2. Overall sebum secretion (excessive/normal/insufficient)
            3. Visible dandruff (none/mild/moderate/severe)
            4. Inflammation signs (erythema/papules/pustules)
            5. Hair density (normal/sparse/loss)
            6. Overall skin texture (smooth/rough/scaly)
            7. Abnormal patches or lesions

            **For Microscopic/Close-up Images** (FOCUS!):
            1. **Follicle Opening Details**:
               - Opening status: clear/mild keratinization/blocked/completely occluded
               - Perifollicluar area: normal/mild redness/obvious inflammation
               - Sebum plugs: none/mild/obvious (white or yellow)

            2. **Keratin & Flake Micro-features**:
               - White granular material (dry flakes) - quantity and size
               - Yellow oily scales (seborrheic) - distribution
               - Stratum corneum thickness (normal/hyperkeratosis/atrophy)

            3. **Sebaceous Gland Activity**:
               - Oiliness level (0-10 scale)
               - Sebum texture (clear/turbid/waxy)
               - Oil distribution pattern (even/concentrated at follicle openings)

            4. **Micro-inflammation Markers**:
               - Small red dots or patches (count, size)
               - Perifollicular redness
               - Tiny pustules or whiteheads

            5. **Scalp Surface Texture**:
               - Skin smoothness (fine/rough/granular)
               - Fine cracks or dryness signs
               - Surface luster (healthy shine/overly oily/dull)

            **Conditions to Diagnose** (list at least potential risks):
            - Seborrheic Dermatitis (oily scalp, yellow scales)
            - Psoriasis (silvery scales, red patches)
            - Folliculitis (red papules, pustules)
            - Alopecia Areata (circular hair loss areas)
            - Androgenetic Alopecia (thinning hair, fine texture)
            - Tinea Capitis (fungal infection, scales, broken hair)
            - Contact Dermatitis (allergy, itching)
            - Telogen Effluvium (diffuse hair loss)
            - Dry or sensitive scalp

            **Health Score Standards** (strict scoring):
            - 90-100: Extremely healthy scalp, no issues
            - 70-89: Minor issues (mild oil, slight dandruff)
            - 50-69: Moderate problems (obvious oil, moderate dandruff, mild inflammation)
            - 30-49: Severe problems (heavy inflammation, hair loss, obvious lesions)
            - 0-29: Extremely severe (immediate medical attention needed)

            **Return Format** (must be valid JSON):
            {
                "image_type": "image type (Microscopic/Close-up/Regular Photo)",
                "scalp_type": "scalp type (oily/dry/normal/combination/sensitive)",
                "microscopic_findings": {
                    "follicle_condition": "follicle status description (microscopic only)",
                    "keratin_buildup": "keratin accumulation status (microscopic only)",
                    "sebum_status": "sebum status description (microscopic only)",
                    "micro_inflammation": "micro-inflammation description (microscopic only)"
                },
                "conditions": [
                    {
                        "name_cn": "Chinese disease name",
                        "name_en": "English Disease Name",
                        "severity": "severity (mild/moderate/severe)",
                        "confidence": confidence_number(0-100),
                        "symptoms": ["specific observed symptom1", "symptom2", "symptom3"],
                        "description": "detailed medical description, including reasoning"
                    }
                ],
                "health_score": health_score(0-100, strict scoring),
                "recommendations": ["specific treatment or care recommendation1", "recommendation2", "recommendation3"],
                "need_doctor": true_or_false (whether medical consultation needed),
                "analysis_summary": "comprehensive analysis summary, including main issues and overall assessment. If microscopic image, clearly state these are observations under magnification."
            }

            **Important Notes**:
            - **ACCEPT microscopic/close-up scalp images as valid images**
            - List any abnormalities, even if very minor
            - Don't easily give 90+ scores, be strict in assessment
            - Even for healthy-looking scalps, provide prevention advice
            - Symptom descriptions should be specific, not vague
            - For microscopic images, describe what you see at micro-level
            """

        try:
            # æ ¹æ®åˆ†ææ¨¡å¼é€‰æ‹©æ¨¡å‹
            preferred_model = language_params.get('preferred_model', None)

            if preferred_model:
                # ç”¨æˆ·æŒ‡å®šæ¨¡å‹
                models_to_try = [preferred_model]
            elif analysis_mode == 'chatgpt':
                # ChatGPTå¯¹é½æ¨¡å¼ - ä¼˜å…ˆä½¿ç”¨æœ€å¥½çš„æ¨¡å‹
                models_to_try = [
                    "gpt-4o",                   # GPT-4 Omni - æœ€æ–°æœ€å¼º
                    "gpt-4-turbo",              # GPT-4 Turbo - é«˜æ€§èƒ½
                ]
            elif analysis_mode == 'economy':
                # ç»æµæ¨¡å¼
                models_to_try = [
                    "gpt-4o-mini",              # GPT-4 Omni Mini - ç»æµå®æƒ 
                    "gpt-4-vision-preview"      # GPT-4 Vision - è¾ƒæ—§ä½†ç¨³å®š
                ]
            else:
                # é»˜è®¤ï¼šå°è¯•å¤šä¸ªæ¨¡å‹
                models_to_try = [
                    "gpt-4o",                   # GPT-4 Omni - æœ€æ–°æœ€å¼º
                    "gpt-4o-mini",              # GPT-4 Omni Mini - ç»æµå®æƒ ï¼Œå¤§å¤šæ•°ç”¨æˆ·å¯ç”¨
                    "gpt-4-turbo",              # GPT-4 Turbo - é«˜æ€§èƒ½
                    "gpt-4-vision-preview"      # GPT-4 Vision - è¾ƒæ—§ä½†ç¨³å®š
                ]

            last_error = None
            response = None
            used_model = None  # è®°å½•ä½¿ç”¨çš„æ¨¡å‹

            for model in models_to_try:
                try:
                    # æ–°æ¨¡å‹ä½¿ç”¨ max_completion_tokensï¼Œæ—§æ¨¡å‹ä½¿ç”¨ max_tokens
                    # GPT-4o åŠæ›´æ–°çš„æ¨¡å‹éœ€è¦ max_completion_tokens
                    uses_new_api = model in ["gpt-4o", "gpt-4o-mini"]

                    # ç¡®ä¿promptæ˜¯UTF-8ç¼–ç çš„å­—ç¬¦ä¸²
                    prompt_text = prompt if isinstance(prompt, str) else str(prompt)

                    # æ„å»ºåŸºç¡€å‚æ•°
                    api_params = {
                        "model": model,
                        "messages": [
                            {
                                "role": "system",
                                "content": "You are a professional dermatologist specializing in scalp health analysis."
                            },
                            {
                                "role": "user",
                                "content": [
                                    {
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:image/png;base64,{img_base64}",
                                            "detail": "high"
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": prompt_text
                                    }
                                ]
                            }
                        ]
                    }

                    # è®¾ç½®é€‚ä¸­çš„temperatureä»¥å¹³è¡¡å‡†ç¡®æ€§å’Œåˆ›é€ æ€§
                    # ChatGPTæ¨¡å¼ä½¿ç”¨è¾ƒä½çš„temperatureç¡®ä¿è¾“å‡ºç¨³å®š
                    # å¯é€šè¿‡analysis_modeå‚æ•°è°ƒæ•´ï¼ˆä¸¥æ ¼æ¨¡å¼ç”¨0.3ï¼Œå¯¹é½æ¨¡å¼ç”¨0.2ï¼‰
                    analysis_mode = language_params.get('analysis_mode', 'balanced') if isinstance(language, dict) else 'balanced'
                    if analysis_mode == 'strict':
                        api_params["temperature"] = 0.3  # ä¸¥æ ¼åŒ»å­¦æ¨¡å¼
                    elif analysis_mode == 'chatgpt':
                        api_params["temperature"] = 0.2  # ChatGPTå¯¹é½æ¨¡å¼ - ä½æ¸©åº¦ç¡®ä¿è¾“å‡ºç¨³å®šä¸€è‡´
                    else:
                        api_params["temperature"] = 0.5  # å¹³è¡¡æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰

                    # æ·»åŠ  seed å‚æ•°è¿›ä¸€æ­¥æé«˜ç¡®å®šæ€§(ä»…æ–°æ¨¡å‹æ”¯æŒ)
                    if uses_new_api:
                        api_params["seed"] = 12345  # å›ºå®šç§å­å€¼

                    # æ ¹æ®æ¨¡å‹ç‰ˆæœ¬æ·»åŠ æ­£ç¡®çš„ token é™åˆ¶å‚æ•°
                    if uses_new_api:
                        api_params["max_completion_tokens"] = 3000
                    else:
                        api_params["max_tokens"] = 3000

                    response = self.client.chat.completions.create(**api_params)
                    used_model = model
                    break  # Success, exit loop

                except Exception as e:
                    error_msg = str(e)
                    last_error = e

                    # If model not found, try next model
                    if "model_not_found" in error_msg or "does not exist" in error_msg:
                        continue
                    else:
                        # Other errors (like API key error), raise immediately
                        raise e

            # If all models failed
            if response is None:
                raise Exception(f"All models unavailable. Last error: {str(last_error)}")

            response_text = response.choices[0].message.content

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ‹’ç»å“åº”
            refusal_phrases = [
                "I'm sorry, I can't help with that",
                "I cannot help with",
                "I can't assist with",
                "I'm unable to",
                "I cannot provide",
                "I cannot analyze",
                "I apologize",
                "I cannot complete",
                "ä¸èƒ½åˆ†æ",
                "æ— æ³•åˆ†æ",
                "æŠ±æ­‰"
            ]

            is_refusal = any(phrase.lower() in response_text.lower() for phrase in refusal_phrases)

            if is_refusal:
                # å¦‚æœAIæ‹’ç»åˆ†æï¼Œè¿”å›ä¸€ä¸ªå‹å¥½çš„é»˜è®¤å“åº”
                result = {
                    "scalp_type": "éœ€è¦é‡æ–°åˆ†æ",
                    "conditions": [],
                    "health_score": 70,
                    "recommendations": [
                        "è¯·ç¡®ä¿ä¸Šä¼ çš„æ˜¯æ¸…æ™°çš„å¤´çš®å›¾åƒ",
                        "å»ºè®®åœ¨å…‰çº¿å……è¶³çš„ç¯å¢ƒä¸‹æ‹æ‘„",
                        "å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·å°è¯•ä½¿ç”¨ä¸åŒçš„åˆ†ææ¨¡å¼"
                    ],
                    "need_doctor": False,
                    "analysis_summary": "ç³»ç»Ÿæš‚æ—¶æ— æ³•åˆ†ææ­¤å›¾åƒã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºå›¾åƒè´¨é‡ã€å…‰çº¿æˆ–æ‹æ‘„è§’åº¦çš„é—®é¢˜ã€‚è¯·ç¡®ä¿ä¸Šä¼ æ¸…æ™°çš„å¤´çš®ç…§ç‰‡ï¼Œå¹¶åœ¨å…‰çº¿å……è¶³çš„ç¯å¢ƒä¸‹æ‹æ‘„ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•å¤´çš®å¥åº·é—®é¢˜ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šçš„çš®è‚¤ç§‘åŒ»ç”Ÿã€‚",
                    "ai_raw_response": response_text,
                    "used_model": used_model,
                    "_was_refused": True
                }
            else:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ChatGPTæ¨¡å¼çš„Markdownè¾“å‡º
                if analysis_mode == 'chatgpt' and '## ğŸ§ ' in response_text:
                    # ChatGPTæ¨¡å¼ - ç›´æ¥ä½¿ç”¨Markdownæ ¼å¼
                    import re

                    # æå–å¥åº·è¯„åˆ†
                    score_match = re.search(r'å¤´çš®å¥åº·å¾—åˆ†ï¼š(\d+)/100', response_text)
                    health_score = int(score_match.group(1)) if score_match else 75

                    # æå–æ˜¯å¦éœ€è¦å°±åŒ»
                    need_doctor = 'æ˜¯å¦éœ€è¦å°±åŒ»ï¼šæ˜¯' in response_text or 'need medical attention: yes' in response_text.lower()

                    # æå–å¤´çš®ç±»å‹ï¼ˆä»åˆæ­¥è§‚å¯Ÿç»“æœä¸­ï¼‰
                    type_match = re.search(r'æ‚¨çš„å¤´çš®æ•´ä½“çŠ¶æ€å±äº([^ã€‚\n]+)', response_text)
                    scalp_type = type_match.group(1) if type_match else "åæ²¹æ€§å¤´çš®"

                    result = {
                        "scalp_type": scalp_type,
                        "conditions": [],  # Markdownæ ¼å¼ä¸éœ€è¦æ¡ä»¶åˆ—è¡¨
                        "health_score": health_score,
                        "confidence": 85,  # ChatGPTæ¨¡å¼é»˜è®¤ç½®ä¿¡åº¦
                        "recommendations": [],  # å»ºè®®å·²åŒ…å«åœ¨Markdownä¸­
                        "need_doctor": need_doctor,
                        "analysis_summary": response_text,  # å®Œæ•´çš„Markdownå†…å®¹
                        "ai_raw_response": response_text,
                        "used_model": used_model,
                        "_is_markdown": True  # æ ‡è®°è¿™æ˜¯Markdownæ ¼å¼
                    }
                else:
                    # åŸæœ‰çš„JSONè§£æé€»è¾‘
                    try:
                        import re
                        # Try to extract JSON
                        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                        if json_match:
                            json_str = json_match.group()
                            result = json.loads(json_str)

                            # Save raw response for debugging
                            result['ai_raw_response'] = response_text
                            # æ·»åŠ ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯
                            result['used_model'] = used_model
                        else:
                            result = {
                                "scalp_type": "Analysis Complete",
                                "conditions": [],
                                "health_score": 50,
                                "recommendations": [response_text],
                                "need_doctor": False,
                                "analysis_summary": response_text,
                                "ai_raw_response": response_text,
                                "used_model": used_model
                            }
                    except json.JSONDecodeError as e:
                        result = {
                            "scalp_type": "Analysis Complete",
                            "conditions": [],
                            "health_score": 50,
                            "recommendations": [response_text],
                            "need_doctor": False,
                            "analysis_summary": response_text,
                            "ai_raw_response": response_text,
                            "parse_error": str(e),
                            "used_model": used_model
                        }

            # æ·»åŠ æ¨¡å‹æ˜¾ç¤ºåç§°
            model_display_names = {
                "gpt-4o": "GPT-4o (Latest)",
                "gpt-4o-mini": "GPT-4o Mini (Economy)",
                "gpt-4-turbo": "GPT-4 Turbo",
                "gpt-4-vision-preview": "GPT-4 Vision"
            }
            result['model_display_name'] = model_display_names.get(used_model, used_model)

            # ä¿å­˜åˆ°ç¼“å­˜
            self._result_cache[image_hash] = result.copy()
            try:
                print(f"[CACHE SAVED] Result cached (hash: {image_hash[:16]}...)")
            except:
                pass  # å¿½ç•¥æ‰“å°é”™è¯¯

            return result

        except Exception as e:
            return {
                "error": f"OpenAI API error: {str(e)}",
                "scalp_type": "Error",
                "conditions": [],
                "health_score": 0,
                "recommendations": ["Unable to analyze image"],
                "need_doctor": False,
                "analysis_summary": f"Error: {str(e)}"
            }

class AIServiceManager:
    """Manager for AI services"""

    @staticmethod
    def get_available_services() -> Dict[str, bool]:
        """Get list of available AI services"""
        return {
            "GPT-4 Vision (OpenAI)": OPENAI_AVAILABLE,
            "Local Analysis (Rule-based)": True
        }

    @staticmethod
    def create_service(service_type: str, api_key: str) -> Optional[AIServiceBase]:
        """Create an AI service instance"""
        if service_type == "GPT-4 Vision (OpenAI)":
            if not api_key:
                st.error("Please provide OpenAI API key")
                return None
            return OpenAIService(api_key)
        else:
            return None

    @staticmethod
    def _normalize_condition(cond: Dict) -> Dict:
        """Normalize a condition dict to include all required fields for UI display"""
        # Disease icon mapping
        icon_map = {
            'è„‚æº¢æ€§çš®ç‚': 'ğŸ”´',
            'seborrheic dermatitis': 'ğŸ”´',
            'é“¶å±‘ç—…': 'ğŸ”µ',
            'psoriasis': 'ğŸ”µ',
            'æ¯›å›Šç‚': 'ğŸŸ¡',
            'folliculitis': 'ğŸŸ¡',
            'æ–‘ç§ƒ': 'âšª',
            'alopecia areata': 'âšª',
            'è„‚æº¢æ€§è„±å‘': 'ğŸŸ ',
            'androgenetic alopecia': 'ğŸŸ ',
            'å¤´ç™£': 'ğŸŸ¢',
            'tinea capitis': 'ğŸŸ¢',
            'æ¥è§¦æ€§çš®ç‚': 'ğŸŸ£',
            'contact dermatitis': 'ğŸŸ£',
            'ä¼‘æ­¢æœŸè„±å‘': 'âš«',
            'telogen effluvium': 'âš«',
        }

        normalized = cond.copy()

        # Add icon if missing
        if 'icon' not in normalized:
            name_cn = normalized.get('name_cn', '').lower()
            name_en = normalized.get('name_en', '').lower()
            normalized['icon'] = 'ğŸ”´'  # default
            for key, icon in icon_map.items():
                if key.lower() in name_cn or key.lower() in name_en:
                    normalized['icon'] = icon
                    break

        # Add common_name if missing
        if 'common_name' not in normalized:
            normalized['common_name'] = normalized.get('name_cn', 'æœªçŸ¥')

        # Ensure all required fields exist
        normalized.setdefault('name_cn', 'æœªçŸ¥ç–¾ç—…')
        normalized.setdefault('name_en', 'Unknown Condition')
        normalized.setdefault('severity', 'ä¸­åº¦')
        normalized.setdefault('description', 'è¯¦ç»†ä¿¡æ¯ä¸å¯ç”¨')

        # Fix confidence if it's 0 or None (AI should provide actual confidence)
        confidence = normalized.get('confidence', None)

        # Debug: Check original confidence value
        original_confidence = confidence

        if confidence is None or confidence == 0 or confidence == '':
            # If no confidence provided, estimate based on severity
            severity = normalized.get('severity', 'ä¸­åº¦')
            if severity in ['é‡åº¦', 'æ™šæœŸ']:
                normalized['confidence'] = 75  # Severe conditions usually have clear signs
            elif severity == 'ä¸­åº¦':
                normalized['confidence'] = 60  # Moderate confidence
            else:
                normalized['confidence'] = 50  # Mild conditions may be less certain
        else:
            # Ensure confidence is an integer
            try:
                normalized['confidence'] = int(float(confidence))
            except (ValueError, TypeError):
                normalized['confidence'] = 50

        return normalized

    @staticmethod
    def combine_analyses(ai_result: Dict, local_result: Dict) -> Dict:
        """Combine AI and local analysis results - AI takes priority"""

        # Start with AI result as base (AI is more accurate)
        combined = ai_result.copy() if ai_result and 'error' not in ai_result else local_result.copy()

        # If AI result is valid, use it as primary source
        if ai_result and 'error' not in ai_result:
            # Map AI conditions to the expected format and normalize them
            ai_conditions = ai_result.get('conditions', [])
            normalized_conditions = [AIServiceManager._normalize_condition(cond) for cond in ai_conditions]
            combined['diagnosed_conditions'] = normalized_conditions

            # Optionally add unique local conditions as supplementary
            if local_result.get('diagnosed_conditions'):
                local_conditions = local_result.get('diagnosed_conditions', [])
                condition_map = {cond.get('name_en', cond.get('name_cn', '')): cond for cond in normalized_conditions}

                for cond in local_conditions:
                    key = cond.get('name_en', cond.get('name_cn', ''))
                    if key not in condition_map:
                        # Add local condition with lower confidence
                        cond_copy = AIServiceManager._normalize_condition(cond)
                        cond_copy['source'] = 'local_analysis'
                        combined['diagnosed_conditions'].append(cond_copy)

            # Use AI recommendations as primary
            combined['concerns'] = ai_result.get('recommendations', [])

            # Add local concerns as supplementary if not already covered
            if local_result.get('concerns'):
                local_concerns = local_result.get('concerns', [])
                combined['concerns'].extend([f"[æœ¬åœ°åˆ†æ] {c}" for c in local_concerns[:2]])

            # Ensure all AI fields are preserved
            if 'analysis_summary' in ai_result:
                combined['ai_analysis'] = ai_result['analysis_summary']

            if 'need_doctor' in ai_result:
                combined['need_doctor'] = ai_result['need_doctor']

            # Add metrics from local analysis if AI doesn't provide them
            if 'metrics' not in combined and 'metrics' in local_result:
                combined['metrics'] = local_result['metrics']

            # Calculate overall confidence from diagnosed conditions
            # å¦‚æœAIç»“æœå·²ç»æœ‰confidenceå€¼ï¼ˆå¦‚ChatGPTæ¨¡å¼ï¼‰ï¼Œåˆ™ä¿ç•™å®ƒ
            if 'confidence' not in ai_result or ai_result.get('confidence', 0) == 0:
                if 'diagnosed_conditions' in combined and combined['diagnosed_conditions']:
                    # Calculate average confidence from all diagnosed conditions
                    confidences = [
                        cond.get('confidence', 0)
                        for cond in combined['diagnosed_conditions']
                    ]
                    if confidences:
                        combined['confidence'] = int(sum(confidences) / len(confidences))
                    else:
                        combined['confidence'] = 0
                else:
                    combined['confidence'] = 0
            # å¦‚æœAIç»“æœå·²æœ‰confidenceï¼Œä¿ç•™åŸå€¼ï¼ˆä¸è¦†ç›–ï¼‰

        return combined

def test_ai_service():
    """Test function for AI services"""
    print("Testing AI Services...")

    # Check available services
    services = AIServiceManager.get_available_services()
    print("\nAvailable Services:")
    for service, available in services.items():
        status = "âœ“ Available" if available else "âœ— Not installed"
        print(f"  - {service}: {status}")

    # Test with a dummy image
    test_image = Image.new('RGB', (300, 300), color=(200, 180, 160))

    # Test Claude if available
    if CLAUDE_AVAILABLE:
        claude_key = os.getenv("ANTHROPIC_API_KEY", "")
        if claude_key:
            print("\nTesting Claude Service...")
            claude_service = ClaudeService(claude_key)
            result = claude_service.analyze_scalp_image(test_image)
            print(f"Result: {json.dumps(result, indent=2, ensure_ascii=False)}")

    # Test OpenAI if available
    if OPENAI_AVAILABLE:
        openai_key = os.getenv("OPENAI_API_KEY", "")
        if openai_key:
            print("\nTesting OpenAI Service...")
            openai_service = OpenAIService(openai_key)
            result = openai_service.analyze_scalp_image(test_image)
            print(f"Result: {json.dumps(result, indent=2, ensure_ascii=False)}")

if __name__ == "__main__":
    test_ai_service()